{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train linear SVM\n",
    "Input: \n",
    "        X, matrix of size #sample x #feature\n",
    "        y, vector of size #sample, either -1 or 1\n",
    "        C, regularizer parameter (default None for hard margin case)\n",
    "Output:\n",
    "        w, weight vector of size #feature\n",
    "        b, intercept, a float\n",
    "'''\n",
    "def train_svm(X, y, C=None):\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Compute Gram matrix\n",
    "    K = linear_kernel(X)\n",
    "\n",
    "    # Solve dual quadratic programming problem\n",
    "    # min{0.5*a.T*P*a+q.T*a}\n",
    "    # subject to G*a<=h and A*a=b\n",
    "    P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "    q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "    A = cvxopt.matrix(y, (1,n_samples))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "    if C is None:\n",
    "        # Hard margin with constraint\n",
    "        # ai >= 0\n",
    "        G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "        h = cvxopt.matrix(np.zeros(n_samples))\n",
    "    else:\n",
    "        # Soft margin with constraint\n",
    "        # 0 <= ai <= C\n",
    "        tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "        tmp2 = np.identity(n_samples)\n",
    "        G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "        tmp1 = np.zeros(n_samples)\n",
    "        tmp2 = np.ones(n_samples) * C\n",
    "        h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "\n",
    "    # Solve the quadratic programming problem\n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    a = np.ravel(solution['x'])\n",
    "\n",
    "    # Support vectors have non zero Lagrange multipliers\n",
    "    sv = a > 1e-5\n",
    "    ind = np.arange(len(a))[sv]\n",
    "    a = a[sv]\n",
    "    sv_y = y[sv]\n",
    "    sv_X = X[sv]\n",
    "\n",
    "    # Calculate intercept b\n",
    "    b = 0\n",
    "    for n in range(len(a)):\n",
    "        b += sv_y[n]\n",
    "        b -= np.sum(a * sv_y * K[ind[n],sv])\n",
    "        b /= len(a)\n",
    "\n",
    "    # Calculate weight vector w\n",
    "    w = np.zeros(n_features)\n",
    "    for n in range(len(a)):\n",
    "        w += a[n] * sv_y[n] * sv_X[n]\n",
    "\n",
    "    return w, b\n",
    "\n",
    "\n",
    "'''\n",
    "Train a variant of linear SVM\n",
    "Input: \n",
    "        X1, matrix of size #sample1 x #feature\n",
    "        y1, vector of size #sample1, either -1 or 1\n",
    "        X2, matrix of size #sample2 x #feature\n",
    "        y2, vector of size #sample2, either -1 or 1\n",
    "        C1, regularizer parameter, control the slack variable of samples from X1\n",
    "        C2, regularizer parameter, control the slack variable of postive samples from X2\n",
    "        C3, regularizer parameter, control the slack variable of negative samples from X2\n",
    "Output:\n",
    "        w, weight vector of size #feature\n",
    "        b, intercept, a float\n",
    "        slack1, slack variable of samples from X1, vector of size #sample1\n",
    "        slack2, slack variable of samples from X2, vector of size #sample2\n",
    "'''\n",
    "def train_variantsvm(X1, y1, X2, y2, C1, C2, C3):\n",
    "\t# Concatenate two data set\n",
    "    X = np.vstack([X1, X2])\n",
    "    y = np.append(y1, y2)\n",
    "\n",
    "    # Create indicator vector mark of size #sample, where\n",
    "    # mark[i] = 0, sample i is from X1\n",
    "    # mark[i] = 1, sample i is from X2 and yi = 1\n",
    "    # mark[i] =-1, sample i is from X2 and yi = -1\n",
    "    n_samples, n_features = X.shape\n",
    "    mark = y.copy()\n",
    "    mark[:X1.shape[0]] = 0\n",
    "\n",
    "    # Compute Gram matrix\n",
    "    K = linear_kernel(X)\n",
    "\n",
    "    # Solve dual quadratic programming problem\n",
    "    # min{0.5*a.T*P*a+q.T*a}\n",
    "    # subject to G*a<=h and A*a=b\n",
    "    P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "    q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "    A = cvxopt.matrix(y, (1,n_samples))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "\n",
    "    # Calculate G and h with constraint \n",
    "    # for xi in X1, 0 <= ai <= C1\n",
    "    # for xi in X2 and yi is 1,  0 <= ai <= C2\n",
    "    # for xi in X2 and yi is -1, 0 <= ai <= C3\n",
    "    tmp=[]\n",
    "    for i in [0,1,-1]:\n",
    "        a=np.zeros(len(mark))\n",
    "        idx= np.where(mark==i)\n",
    "        if idx[0].size!=0:\n",
    "            a[idx]=1\n",
    "            tmp.append(a)\n",
    "    C = [C1, C2, C3]\n",
    "    gi=[]\n",
    "    hi=[]\n",
    "    for bi, c in zip(tmp, C):\n",
    "        tmp1 = np.diag(bi) * -1\n",
    "        tmp2 = np.diag(bi)\n",
    "        gi.append(np.vstack((tmp1, tmp2)))\n",
    "        tmp1 = np.zeros(len(bi))\n",
    "        tmp2 = np.ones(len(bi)) * c\n",
    "        hi.append(np.hstack((tmp1, tmp2)))\n",
    "    G= cvxopt.matrix(np.vstack(gi))\n",
    "    h= cvxopt.matrix(np.hstack(hi))\n",
    "\n",
    "\n",
    "    # Solve the quadratic programming problem\n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    a = np.ravel(solution['x'])\n",
    "\n",
    "    # Support vectors have non zero Lagrange multipliers\n",
    "    sv = a > 1e-5\n",
    "    ind = np.arange(len(a))[sv]\n",
    "    a = a[sv]\n",
    "    sv_y = y[sv]\n",
    "    sv_X = X[sv]\n",
    "\n",
    "    # Caculate intercept b\n",
    "    b = 0\n",
    "    for n in range(len(a)):\n",
    "        b += sv_y[n]\n",
    "        b -= np.sum(a * sv_y * K[ind[n],sv])\n",
    "        b /= len(a)\n",
    "\n",
    "    # Calculate weight vector w\n",
    "    w = np.zeros(n_features)\n",
    "    for n in range(len(a)):\n",
    "        w += a[n] * sv_y[n] * sv_X[n]\n",
    "\n",
    "    # Get slack variable\n",
    "    slack = np.zeros(n_samples)\n",
    "    for n in range(len(a)):\n",
    "        if abs(C1 - a[n]) < 1e-5 or abs(C2 - a[n]) < 1e-5 or abs(C3 - a[n]) < 1e-5:\n",
    "            slack[ind[n]] = abs(sv_y[n] * (np.dot(sv_X[n], w) + b))    \n",
    "\n",
    "    return w, b, slack[:X1.shape[0]], slack[X1.shape[0]:]\n",
    "\n",
    "\n",
    "'''\n",
    "Train linear transductive SVM\n",
    "Input: \n",
    "        X1, matrix of size #sample1 x #feature\n",
    "        y1, vector of size #sample1, either -1 or 1\n",
    "        X2, matrix of size #sample2 x #feature\n",
    "        C1, regularizer parameter, control the slack variable of samples from X1\n",
    "        C2, regularizer parameter, control the slack variable of samples from X2\n",
    "        p,  percentage of positive samples in unlabeled data X2, [0, 1]\n",
    "Output:\n",
    "        w, weight vector of size #feature\n",
    "        b, intercept, a float\n",
    "'''\n",
    "def train_tsvm(X1, y1, X2, C1, C2, p):\n",
    "    \n",
    "    # 1. Get number of positive samples\n",
    "    num_pos = int(X2.shape[0] * p)\n",
    "\n",
    "    # 2. Train standard SVM using labeled samples\n",
    "    w, b = train_svm(X1, y1, C1)\n",
    "    \n",
    "    # 3. The num_pos test examples from X2 with highest value of w*x+b are assigned to 1\n",
    "    # The rest of examples from X2 are assigned to -1\n",
    "    val=np.zeros(train_unlabel_X.shape[0])\n",
    "    for i in range(train_unlabel_X.shape[0]):\n",
    "        val[i]= w.dot(train_unlabel_X[i,:])+b\n",
    "    y2=val.copy()\n",
    "    y2[np.argsort(val)[::-1][:num_pos]]= 1\n",
    "    y2[np.argsort(val)[::-1][num_pos:]]= -1\n",
    "    \n",
    "    # 4. Retrain with label switching\n",
    "    C_neg = 1e-5\n",
    "    C_pos = 1e-5 * num_pos / (X2.shape[0] - num_pos)\n",
    "    while C_neg < C2 or C_pos < C2:\n",
    "        \n",
    "        # 5. Retrain the variant of SVM\n",
    "        w, b, slack1, slack2= train_variantsvm(X1, y1, X2, y2, C1, C_neg, C_pos)\n",
    "        \n",
    "        # 6. Take a positive and negative example, switch their labels\n",
    "        tmp_list=[]\n",
    "        for i in range(len(y2)):\n",
    "            for j in range(i+1, len(y2)):\n",
    "                tmp_list.append((i,j))\n",
    "        for l,m in tmp_list:\n",
    "            while y2[l]*y2[l+1]<0 and slack2[l]>0 and slack2[l+1]>0 and slack2[l]+slack2[l+1]>2 :\n",
    "                y2[l]= -y2[l]\n",
    "                y2[m]= -y1[m]\n",
    "                w, b, slack1, slack2= train_variantsvm(X1, y1, X2, y2, C1, C_neg, C_pos)\n",
    "        # 7. Increase the value of C_neg and C_pos\n",
    "        C_neg= min(2*C_neg, C1)\n",
    "        C_pos= min(2*C_pos, C1)\n",
    "\n",
    "    # 8. Return the learned model\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X (610, 9930)\n",
      "train_y (610,)\n",
      "test_X (600, 9930)\n",
      "test_y (600,)\n"
     ]
    }
   ],
   "source": [
    "test = load_svmlight_file('test.dat')\n",
    "train = load_svmlight_file('train.dat')\n",
    "test_X = np.array(test[0].todense())\n",
    "test_y = test[1]\n",
    "train_X = np.array(train[0].todense())\n",
    "train_y = train[1]\n",
    "\n",
    "print('train_X', train_X.shape)\n",
    "print('train_y', train_y.shape)\n",
    "print('test_X', test_X.shape)\n",
    "print('test_y', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inductive SVM\n",
      "Accuracy: 0.855\n",
      "\n",
      "Inductive SVM variate\n",
      "Accuracy: 0.855\n",
      "\n",
      "Transductive SVM\n",
      "Accuracy: 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "# Extract labeled and unlabeled training samples\n",
    "# 1, -1 indicate labeled samples\n",
    "# 0 indicates unlabeled samples\n",
    "train_label_X = train_X[np.where(train_y!=0)]\n",
    "train_label_y = train_y[np.where(train_y!=0)]\n",
    "train_unlabel_X = train_X[np.where(train_y==0)]\n",
    "\n",
    "# Perform inductive linear SVM\n",
    "print(\"Inductive SVM\")\n",
    "w, b = train_svm(train_label_X, train_label_y, C=1)\n",
    "pred_y = np.sign(np.dot(test_X, w) + b)\n",
    "print(\"Accuracy: %s\\n\" % accuracy_score(test_y, pred_y))\n",
    "\n",
    "# Split the training set into two parts\n",
    "n = train_label_X.shape[0] // 2\n",
    "train_label_X1 = train_label_X[:n]\n",
    "train_label_y1 = train_label_y[:n]\n",
    "train_label_X2 = train_label_X[n:]\n",
    "train_label_y2 = train_label_y[n:]\n",
    "\n",
    "# Perform a variant of inductive linear SVM\n",
    "print(\"Inductive SVM variate\")\n",
    "w, b, slack1, slack2= train_variantsvm(train_label_X1, train_label_y1, train_label_X2, train_label_y2, C1=1, C2=1, C3=1)\n",
    "pred_y = np.sign(np.dot(test_X, w) + b)\n",
    "print(\"Accuracy: %s\\n\" % accuracy_score(test_y, pred_y))\n",
    "\n",
    "# Perform transductive linear SVM\n",
    "print(\"Transductive SVM\")\n",
    "w, b = train_tsvm(train_label_X, train_label_y, train_unlabel_X, C1=1, C2=0.01, p=0.5)\n",
    "pred_y = np.sign(np.dot(test_X, w) + b)\n",
    "print(\"Accuracy: %s\" % accuracy_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
